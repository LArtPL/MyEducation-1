{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c sf-dl-car-classification\n",
    "# !unzip sf-dl-car-classification.zip\n",
    "# !unzip train.zip\n",
    "# !unzip test.zip\n",
    "# !rm sf-dl-car-classification.zip\n",
    "# !rm train.zip\n",
    "# !rm test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DataParallel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import cv2\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS               = 10\n",
    "BATCH_SIZE           = 16\n",
    "LR                   = 1e-3\n",
    "VAL_SPLIT            = 0.1\n",
    "\n",
    "CLASS_NUM            = 10\n",
    "IMG_SIZE             = 320 # 320, 520\n",
    "IMG_CHANNELS         = 3\n",
    "input_shape          = (IMG_SIZE-10, IMG_SIZE-10, IMG_CHANNELS)\n",
    "\n",
    "PATH = './data'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_filepaths, transform=None, data='train'):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images_filepaths.iloc[idx, :]\n",
    "        label = img_info.Category\n",
    "        if self.data == 'train':\n",
    "            image_filepath = os.path.join('./data', self.data, str(label), img_info.Id)\n",
    "        else:\n",
    "            image_filepath = os.path.join('./data', self.data, img_info.Id)\n",
    "            \n",
    "        image = cv2.imread(image_filepath)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATIONS_train = albumentations.Compose([\n",
    "    albumentations.Resize(height=IMG_SIZE, width=IMG_SIZE),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.Rotate(limit=10, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n",
    "    albumentations.CenterCrop(height=IMG_SIZE-10, width=IMG_SIZE-10),\n",
    "    albumentations.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05),\n",
    "    albumentations.GaussianBlur(p=0.1),\n",
    "    albumentations.HueSaturationValue(p=0.5),\n",
    "    albumentations.RGBShift(p=0.5),\n",
    "    albumentations.FancyPCA(alpha=0.1),\n",
    "    albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "AUGMENTATIONS_test = albumentations.Compose([\n",
    "    albumentations.Resize(height=IMG_SIZE, width=IMG_SIZE),\n",
    "    albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': lambda image: AUGMENTATIONS_train(image=image),\n",
    "    'val': lambda image: AUGMENTATIONS_test(image=image),\n",
    "    'test': lambda image: AUGMENTATIONS_test(image=image),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "\n",
    "image_locations = pd.read_csv(\"train.csv\")\n",
    "test_locations = pd.read_csv(\"sample-submission.csv\")\n",
    "\n",
    "\n",
    "image_locations = image_locations.sample(frac=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(images_filepaths=image_locations[:15000], transform=data_transforms['train'])\n",
    "val_dataset = MyDataset(images_filepaths=image_locations[15000:], transform=data_transforms['val'])\n",
    "test_dataset = MyDataset(images_filepaths=test_locations, transform=data_transforms['test'], data='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {'train': train_dataset,\n",
    "                  'val': val_dataset,\n",
    "                  'test': test_dataset}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset),\n",
    "    'test': len(test_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True)\n",
    "              for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62488e8b8eb44d89a01b897e72e61df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    plt.close()\n",
    "#     plt.figure(figsize=(6, 4), dpi=150)\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet_b7(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=num_classes)\n",
    "        \n",
    "        self.classifier_layer = nn.Sequential(\n",
    "            nn.BatchNorm1d(2560),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2560, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.model.extract_features(inputs)\n",
    "\n",
    "        # Pooling and final linear layer\n",
    "        x = self.model._avg_pooling(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.classifier_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "model_ft = DataParallel(EfficientNet_b7(num_classes=CLASS_NUM), device_ids=[0, 1], output_device=0)\n",
    "model_ft.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сперва сделаем Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_ft._modules['module'].model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=1e-3)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.5334 Acc: 0.4752\n",
      "val Loss: 0.8561 Acc: 0.6970\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.3920 Acc: 0.5421\n",
      "val Loss: 0.8094 Acc: 0.6952\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.4064 Acc: 0.5456\n",
      "val Loss: 0.7734 Acc: 0.7255\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.3634 Acc: 0.5651\n",
      "val Loss: 0.7455 Acc: 0.7273\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.3505 Acc: 0.5674\n",
      "val Loss: 0.7681 Acc: 0.7094\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.3062 Acc: 0.5777\n",
      "val Loss: 0.6996 Acc: 0.7362\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.2767 Acc: 0.5805\n",
      "val Loss: 0.6927 Acc: 0.7611\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.2708 Acc: 0.5787\n",
      "val Loss: 0.6796 Acc: 0.7558\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.2251 Acc: 0.5963\n",
      "val Loss: 0.7163 Acc: 0.7540\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.2471 Acc: 0.5875\n",
      "val Loss: 0.6976 Acc: 0.7469\n",
      "\n",
      "Training complete in 66m 28s\n",
      "Best val Acc: 0.761141\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# А затем сделаем Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сперва с половиной слоёв, обученных на ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE           = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = len(list(model_ft._modules['module'].model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in list(model_ft._modules['module'].model.parameters())[n_layers // 2:]:\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=1e-4)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.4663 Acc: 0.8481\n",
      "val Loss: 0.1047 Acc: 0.9679\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.1862 Acc: 0.9415\n",
      "val Loss: 0.0652 Acc: 0.9786\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.1330 Acc: 0.9547\n",
      "val Loss: 0.0673 Acc: 0.9715\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.1140 Acc: 0.9632\n",
      "val Loss: 0.0733 Acc: 0.9697\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0921 Acc: 0.9688\n",
      "val Loss: 0.0615 Acc: 0.9822\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0612 Acc: 0.9791\n",
      "val Loss: 0.0507 Acc: 0.9768\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0530 Acc: 0.9813\n",
      "val Loss: 0.0436 Acc: 0.9786\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0501 Acc: 0.9833\n",
      "val Loss: 0.0630 Acc: 0.9804\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0415 Acc: 0.9875\n",
      "val Loss: 0.0780 Acc: 0.9679\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0325 Acc: 0.9889\n",
      "val Loss: 0.0549 Acc: 0.9768\n",
      "\n",
      "Training complete in 91m 59s\n",
      "Best val Acc: 0.982175\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_ft.state_dict(), './pytorch_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.load_state_dict(torch.load('./pytorch_model.pth', map_location='cpu'),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А затем и на всей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE           = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in list(model_ft._modules['module'].model.parameters()):\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=1e-5)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9513\n",
      "val Loss: 0.0661 Acc: 0.9786\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0897 Acc: 0.9695\n",
      "val Loss: 0.0554 Acc: 0.9804\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0722 Acc: 0.9748\n",
      "val Loss: 0.0485 Acc: 0.9840\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0637 Acc: 0.9779\n",
      "val Loss: 0.0466 Acc: 0.9786\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0539 Acc: 0.9807\n",
      "val Loss: 0.0414 Acc: 0.9840\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0475 Acc: 0.9823\n",
      "val Loss: 0.0447 Acc: 0.9840\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0412 Acc: 0.9869\n",
      "val Loss: 0.0456 Acc: 0.9857\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0402 Acc: 0.9869\n",
      "val Loss: 0.0422 Acc: 0.9840\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.9886\n",
      "val Loss: 0.0429 Acc: 0.9857\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0331 Acc: 0.9893\n",
      "val Loss: 0.0456 Acc: 0.9840\n",
      "\n",
      "Training complete in 91m 35s\n",
      "Best val Acc: 0.985740\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Condatorch",
   "language": "python",
   "name": "condatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
